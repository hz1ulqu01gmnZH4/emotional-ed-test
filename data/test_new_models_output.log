Using device: cuda

======================================================================
TESTING: HuggingFaceTB/SmolLM3-3B
======================================================================

Loading model...
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.00s/it]
  Layers: 36, Hidden size: 2048

Extracting directions from layers [0, 9, 18, 27, 34]...

Testing 5 layers × 4 scales...
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.

======================================================================
RESULTS: HuggingFaceTB/SmolLM3-3B
======================================================================

Layer    Scale    Fear       Curiosity    Anger      Joy        Avg |d|   
--------------------------------------------------------------------
0        0.0     0.25      0.08      0.00      0.17      baseline  
0        3.0     +0.08      +0.25      +0.00      -0.38      0.18
0        5.0     +0.00      +0.00      +0.00      +0.00      0.00
0        7.0     -0.08      +0.49      +0.00      +0.16      0.18
9        0.0     0.25      0.08      0.00      0.17      baseline  
9        3.0     -0.32      +0.36      +0.00      -0.27      0.24
9        5.0     -0.18      +0.49      +0.73      -0.27      0.42
9        7.0     +0.00      +0.31      +0.43      -0.17      0.23
18       0.0     0.25      0.08      0.00      0.17      baseline  
18       3.0     +0.08      +0.25      +0.29      -0.17      0.20
18       5.0     +0.27      +0.14      +0.00      -0.08      0.12
18       7.0     +0.00      +0.52      +0.29      +0.00      0.20
27       0.0     0.25      0.08      0.00      0.17      baseline  
27       3.0     +0.09      +0.49      +0.00      -0.27      0.21
27       5.0     +0.45      +0.52      +0.29      -0.17      0.36
27       7.0     +0.45      +0.36      +0.00      -0.17      0.24
34       0.0     0.25      0.08      0.00      0.17      baseline  
34       3.0     +0.15      +0.00      +0.00      -0.17      0.08
34       5.0     +0.09      +0.40      +0.00      -0.38      0.22
34       7.0     +0.49      +0.25      +0.00      -0.38      0.28

======================================================================
BEST CONFIGURATION
======================================================================

  ⚪ SMALL-MEDIUM EFFECT
     Layer: 9, Scale: 5.0
     Avg |d| = 0.417

  Sample outputs at best config:

  FEAR steering:
    ' a series of peculiar symbols etched into the walls. The air was thick with an unsettling aura, the ...'

  JOY steering:
    ' the intricate carvings that adorned the ceiling. This was our first glimpse of the grandeur that th...'

======================================================================
TESTING: Qwen/Qwen3-4B
======================================================================

Loading model...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.25s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]
  Layers: 36, Hidden size: 2560

Extracting directions from layers [0, 9, 18, 27, 34]...

Testing 5 layers × 4 scales...

======================================================================
RESULTS: Qwen/Qwen3-4B
======================================================================

Layer    Scale    Fear       Curiosity    Anger      Joy        Avg |d|   
--------------------------------------------------------------------
0        0.0     0.62      0.12      0.12      0.17      baseline  
0        3.0     -0.34      +0.00      -0.40      +0.12      0.22
0        5.0     -0.39      -0.14      -0.40      +0.07      0.25
0        7.0     -0.85      -0.14      +0.00      +0.09      0.27
9        0.0     0.62      0.12      0.12      0.17      baseline  
9        3.0     -0.11      +0.00      -0.11      -0.42      0.16
9        5.0     -0.15      +0.10      -0.24      +0.00      0.12
9        7.0     -0.53      -0.30      -0.24      -0.12      0.30
18       0.0     0.62      0.12      0.12      0.17      baseline  
18       3.0     -0.18      +0.26      -0.24      +0.16      0.21
18       5.0     -0.28      +0.10      -0.40      +0.09      0.22
18       7.0     -0.28      +0.55      -0.40      +0.09      0.33
27       0.0     0.62      0.12      0.12      0.17      baseline  
27       3.0     +0.10      +0.00      +0.00      -0.12      0.05
27       5.0     +0.00      +0.10      +0.00      -0.25      0.09
27       7.0     +0.00      +0.20      +0.00      -0.25      0.11
34       0.0     0.62      0.12      0.12      0.17      baseline  
34       3.0     +0.14      +0.20      +0.00      +0.00      0.08
34       5.0     +0.14      +0.20      +0.00      -0.12      0.11
34       7.0     +0.09      +0.29      +0.00      -0.12      0.12

======================================================================
BEST CONFIGURATION
======================================================================

  ⚪ SMALL-MEDIUM EFFECT
     Layer: 18, Scale: 7.0
     Avg |d| = 0.328

  Sample outputs at best config:

  FEAR steering:
    ' the painting of a young girl on the wall. The painting was of a girl with a smile and a bright red ...'

  JOY steering:
    ' the faint smell of something burning.  What could be the possible causes of this smell?  Also, I sa...'

======================================================================
FINAL COMPARISON
======================================================================

Model                          Layer    Scale    Avg |d|    Verdict        
-----------------------------------------------------------------------
HuggingFaceTB/SmolLM3-3B       9        5.0      0.417      SMALL-MEDIUM   
Qwen/Qwen3-4B                  18       7.0      0.328      SMALL-MEDIUM   

Results saved to: data/new_models_results.json

======================================================================
RECOMMENDATION: HuggingFaceTB/SmolLM3-3B
  Effect size: 0.417 (SMALL-MEDIUM)
======================================================================
